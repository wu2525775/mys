{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "from model import TextRNN\n",
    "from cnews_loader import get_labels,get_vocab,process_file\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "train_file = 'cnews.train.txt'\n",
    "test_file = 'cnews.test.txt'\n",
    "val_file = 'cnews.val.txt'\n",
    "vocab_file = 'cnews.vocab.txt'\n",
    "\n",
    "def train():\n",
    "    model = TextRNN().cuda()#设置使用GPU\n",
    "    Loss = nn.CrossEntropyLoss()#定义损失函数(此标准将LogSoftMax和NLLLoss集成到一个类中。\n",
    "                                            #当训练一个多类分类器的时候，这个方法是十分有用的。)                                            \n",
    "    optimer = optim.Adam(model.parameters(), lr=0.001)#model.parameters():待优化参数的iterable或者是定义了参数组的dict\n",
    "    #当网络的评价指标不在提升的时候，可以通过降低网络的学习率来提高网络性能                                                  #lr=0.001:学习率\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimer,#optimer指的是网络的优化器\n",
    "                                                           mode='max', #mode (str) ，可选择‘min’或者‘max’，min表示当监控量停止下降的时候，学习率将减小，max表示当监控量停止上升的时候，学习率将减小。默认值为‘min’\n",
    "                                                           patience=5,#容忍网路的性能不提升的次数，高于这个次数就降低学习率\n",
    "                                                           verbose=True,#如果为True，则为每次更新向stdout输出一条消息。 默认值：False\n",
    "                                                           min_lr=1.e-6)# 学习率下限\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    \n",
    "    total_iter=0\n",
    "    for epoch in range(30):\n",
    "        \n",
    "        model.train()\n",
    "        for step,(batch_x, batch_y) in enumerate(train_loader):\n",
    "            \n",
    "            \n",
    "            \n",
    "            total_iter+=1\n",
    "            x = batch_x.cuda()\n",
    "            y = batch_y.cuda().long()\n",
    "            y_label= torch.argmax(y,1)\n",
    "            \n",
    "            out = model(x)\n",
    "            loss = Loss(out, y_label)\n",
    "            optimer.zero_grad()#梯度清零\n",
    "            loss.backward()#反向传播\n",
    "            optimer.step()\n",
    "            \n",
    "            preds=torch.softmax(out,dim=1)\n",
    "            acc_train = np.mean((torch.argmax(preds,1) == torch.argmax(y,1)).cpu().numpy())\n",
    "            \n",
    "            if step%100==0:\n",
    "               \n",
    "                print(\"epoch:{},step:{},acc_train:{},loss_train:{}\".format(epoch,total_iter,acc_train,loss))\n",
    "            \n",
    "        acc_val_val=0\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        for step,(batch_x, batch_y) in enumerate(val_loader):\n",
    "            \n",
    "            x = batch_x.cuda()\n",
    "            y = batch_y.cuda().long()\n",
    "            y_label= torch.argmax(y,1)\n",
    "            out = model(x)\n",
    "            \n",
    "            preds=torch.softmax(out,dim=1)\n",
    "            acc_val = np.mean((torch.argmax(preds,1) == torch.argmax(y,1)).cpu().numpy())\n",
    "            acc_val_val+=acc_val\n",
    "            if acc_val > best_val_acc:\n",
    "                torch.save(model.state_dict(), './model_params.pkl')\n",
    "                best_val_acc = acc_val\n",
    "        acc_val_=acc_val_val/(step+1)\n",
    "        print(\"epoch:{},step:{},acc_val:{}\".format(epoch,total_iter,acc_val_))\n",
    "        scheduler.step(acc_val_)\n",
    "\n",
    "            \n",
    "# 获取文本的类别及其对应id的字典\n",
    "label, label_dict = get_labels()\n",
    "# 获取训练文本中所有出现过的字及其所对应的id\n",
    "word, word_dict = get_vocab('cnews.vocab.txt')\n",
    "# 数据加载及分批\n",
    "# 获取训练数据每个字的id和对应标签的one-hot形式\n",
    "x_train, y_train = process_file('cnews.train.txt', word_dict, label_dict, 600)\n",
    "x_val, y_val = process_file('cnews.val.txt', word_dict, label_dict, 600)\n",
    "x_test, y_test = process_file('cnews.test.txt', word_dict, label_dict, 600)\n",
    "\n",
    "x_train, y_train = torch.LongTensor(x_train),torch.Tensor(y_train)\n",
    "x_val,y_val = torch.LongTensor(x_val),torch.Tensor(y_val)\n",
    "\n",
    "train_dataset = Data.TensorDataset(x_train,y_train)\n",
    "train_loader = Data.DataLoader(dataset=train_dataset,batch_size=128,\n",
    "                              shuffle=True,num_workers=2)\n",
    "val_dataset = Data.TensorDataset(x_val,y_val)\n",
    "val_loader = Data.DataLoader(dataset=val_dataset,batch_size=128,\n",
    "                            shuffle=True,num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,step:1,acc_train:0.078125,loss_train:2.3147175312042236\n",
      "epoch:0,step:101,acc_train:0.5546875,loss_train:1.3804938793182373\n",
      "epoch:0,step:201,acc_train:0.734375,loss_train:0.9010396003723145\n",
      "epoch:0,step:301,acc_train:0.7890625,loss_train:0.6187540888786316\n",
      "epoch:0,step:391,acc_val:0.8076171875\n",
      "epoch:1,step:392,acc_train:0.78125,loss_train:0.5959916710853577\n",
      "epoch:1,step:492,acc_train:0.8515625,loss_train:0.45020559430122375\n",
      "epoch:1,step:592,acc_train:0.828125,loss_train:0.5411161184310913\n",
      "epoch:1,step:692,acc_train:0.8671875,loss_train:0.39501336216926575\n",
      "epoch:1,step:782,acc_val:0.851171875\n",
      "epoch:2,step:783,acc_train:0.9140625,loss_train:0.27249738574028015\n",
      "epoch:2,step:883,acc_train:0.9453125,loss_train:0.1866016834974289\n",
      "epoch:2,step:983,acc_train:0.9453125,loss_train:0.24887068569660187\n",
      "epoch:2,step:1083,acc_train:0.8671875,loss_train:0.36486995220184326\n",
      "epoch:2,step:1173,acc_val:0.875\n",
      "epoch:3,step:1174,acc_train:0.90625,loss_train:0.44178131222724915\n",
      "epoch:3,step:1274,acc_train:0.9296875,loss_train:0.18842607736587524\n",
      "epoch:3,step:1374,acc_train:0.921875,loss_train:0.2644396424293518\n",
      "epoch:3,step:1474,acc_train:0.8984375,loss_train:0.28665071725845337\n",
      "epoch:3,step:1564,acc_val:0.8876953125\n",
      "epoch:4,step:1565,acc_train:0.9140625,loss_train:0.18642941117286682\n",
      "epoch:4,step:1665,acc_train:0.9765625,loss_train:0.08607179671525955\n",
      "epoch:4,step:1765,acc_train:0.9453125,loss_train:0.16171693801879883\n",
      "epoch:4,step:1865,acc_train:0.9296875,loss_train:0.1649358719587326\n",
      "epoch:4,step:1955,acc_val:0.8833984375\n",
      "epoch:5,step:1956,acc_train:0.921875,loss_train:0.23065735399723053\n",
      "epoch:5,step:2056,acc_train:0.9296875,loss_train:0.2077290117740631\n",
      "epoch:5,step:2156,acc_train:0.921875,loss_train:0.2086232602596283\n",
      "epoch:5,step:2256,acc_train:0.9375,loss_train:0.2028370052576065\n",
      "epoch:5,step:2346,acc_val:0.8767578125\n",
      "epoch:6,step:2347,acc_train:0.9296875,loss_train:0.17206645011901855\n",
      "epoch:6,step:2447,acc_train:0.9453125,loss_train:0.20479577779769897\n",
      "epoch:6,step:2547,acc_train:0.9609375,loss_train:0.11176574230194092\n",
      "epoch:6,step:2647,acc_train:0.9453125,loss_train:0.21780039370059967\n",
      "epoch:6,step:2737,acc_val:0.8931640625\n",
      "epoch:7,step:2738,acc_train:0.9453125,loss_train:0.13445375859737396\n",
      "epoch:7,step:2838,acc_train:0.9453125,loss_train:0.15519529581069946\n",
      "epoch:7,step:2938,acc_train:0.96875,loss_train:0.08262903988361359\n",
      "epoch:7,step:3038,acc_train:0.921875,loss_train:0.18674856424331665\n",
      "epoch:7,step:3128,acc_val:0.890234375\n",
      "epoch:8,step:3129,acc_train:0.953125,loss_train:0.12391705065965652\n",
      "epoch:8,step:3229,acc_train:0.96875,loss_train:0.15104174613952637\n",
      "epoch:8,step:3329,acc_train:0.9609375,loss_train:0.08704711496829987\n",
      "epoch:8,step:3429,acc_train:0.9375,loss_train:0.16095119714736938\n",
      "epoch:8,step:3519,acc_val:0.895703125\n",
      "epoch:9,step:3520,acc_train:0.9765625,loss_train:0.0630839541554451\n",
      "epoch:9,step:3620,acc_train:0.9375,loss_train:0.11405228078365326\n",
      "epoch:9,step:3720,acc_train:0.953125,loss_train:0.11727174371480942\n",
      "epoch:9,step:3820,acc_train:0.9921875,loss_train:0.03260169178247452\n",
      "epoch:9,step:3910,acc_val:0.898828125\n",
      "epoch:10,step:3911,acc_train:0.9296875,loss_train:0.16016706824302673\n",
      "epoch:10,step:4011,acc_train:0.9765625,loss_train:0.06090456247329712\n",
      "epoch:10,step:4111,acc_train:0.984375,loss_train:0.0656147301197052\n",
      "epoch:10,step:4211,acc_train:0.9375,loss_train:0.2264273762702942\n",
      "epoch:10,step:4301,acc_val:0.88125\n",
      "epoch:11,step:4302,acc_train:0.9453125,loss_train:0.1666593849658966\n",
      "epoch:11,step:4402,acc_train:0.953125,loss_train:0.11997009813785553\n",
      "epoch:11,step:4502,acc_train:0.9765625,loss_train:0.11384585499763489\n",
      "epoch:11,step:4602,acc_train:0.953125,loss_train:0.10638687759637833\n",
      "epoch:11,step:4692,acc_val:0.8955078125\n",
      "epoch:12,step:4693,acc_train:0.9921875,loss_train:0.031047765165567398\n",
      "epoch:12,step:4793,acc_train:0.9296875,loss_train:0.14221307635307312\n",
      "epoch:12,step:4893,acc_train:0.9765625,loss_train:0.10628852248191833\n",
      "epoch:12,step:4993,acc_train:0.96875,loss_train:0.0979626476764679\n",
      "epoch:12,step:5083,acc_val:0.8892578125\n",
      "epoch:13,step:5084,acc_train:0.9453125,loss_train:0.12703680992126465\n",
      "epoch:13,step:5184,acc_train:0.96875,loss_train:0.08711622655391693\n",
      "epoch:13,step:5284,acc_train:0.96875,loss_train:0.08342728018760681\n",
      "epoch:13,step:5384,acc_train:0.984375,loss_train:0.06801822781562805\n",
      "epoch:13,step:5474,acc_val:0.8896484375\n",
      "epoch:14,step:5475,acc_train:0.9765625,loss_train:0.043960221111774445\n",
      "epoch:14,step:5575,acc_train:0.9921875,loss_train:0.04385300725698471\n",
      "epoch:14,step:5675,acc_train:0.9765625,loss_train:0.04587923735380173\n",
      "epoch:14,step:5775,acc_train:0.96875,loss_train:0.0606159083545208\n",
      "epoch:14,step:5865,acc_val:0.889453125\n",
      "epoch:15,step:5866,acc_train:0.9921875,loss_train:0.03259914740920067\n",
      "epoch:15,step:5966,acc_train:0.984375,loss_train:0.05423721671104431\n",
      "epoch:15,step:6066,acc_train:0.96875,loss_train:0.14137384295463562\n",
      "epoch:15,step:6166,acc_train:1.0,loss_train:0.021004904061555862\n",
      "epoch:15,step:6256,acc_val:0.89375\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-04.\n",
      "epoch:16,step:6257,acc_train:0.9453125,loss_train:0.12497717887163162\n",
      "epoch:16,step:6357,acc_train:0.9453125,loss_train:0.16634799540042877\n",
      "epoch:16,step:6457,acc_train:0.953125,loss_train:0.10264384001493454\n",
      "epoch:16,step:6557,acc_train:1.0,loss_train:0.0199675802141428\n",
      "epoch:16,step:6647,acc_val:0.8994140625\n",
      "epoch:17,step:6648,acc_train:0.9921875,loss_train:0.03232535719871521\n",
      "epoch:17,step:6748,acc_train:0.9609375,loss_train:0.12388409674167633\n",
      "epoch:17,step:6848,acc_train:0.984375,loss_train:0.05367916077375412\n",
      "epoch:17,step:6948,acc_train:0.984375,loss_train:0.05362251028418541\n",
      "epoch:17,step:7038,acc_val:0.901953125\n",
      "epoch:18,step:7039,acc_train:0.96875,loss_train:0.11476945877075195\n",
      "epoch:18,step:7139,acc_train:0.9765625,loss_train:0.06677423417568207\n",
      "epoch:18,step:7239,acc_train:0.9765625,loss_train:0.07788758724927902\n",
      "epoch:18,step:7339,acc_train:1.0,loss_train:0.02976706251502037\n",
      "epoch:18,step:7429,acc_val:0.8919921875\n",
      "epoch:19,step:7430,acc_train:0.96875,loss_train:0.10707724094390869\n",
      "epoch:19,step:7530,acc_train:0.9765625,loss_train:0.1079750806093216\n",
      "epoch:19,step:7630,acc_train:0.9921875,loss_train:0.01643550954759121\n",
      "epoch:19,step:7730,acc_train:0.96875,loss_train:0.06452319025993347\n",
      "epoch:19,step:7820,acc_val:0.89609375\n",
      "epoch:20,step:7821,acc_train:0.96875,loss_train:0.06175205484032631\n",
      "epoch:20,step:7921,acc_train:0.984375,loss_train:0.09583483636379242\n",
      "epoch:20,step:8021,acc_train:0.9609375,loss_train:0.07217063009738922\n",
      "epoch:20,step:8121,acc_train:0.984375,loss_train:0.03424534201622009\n",
      "epoch:20,step:8211,acc_val:0.901953125\n",
      "epoch:21,step:8212,acc_train:0.96875,loss_train:0.13322919607162476\n",
      "epoch:21,step:8312,acc_train:0.984375,loss_train:0.04530195891857147\n",
      "epoch:21,step:8412,acc_train:0.984375,loss_train:0.045703478157520294\n",
      "epoch:21,step:8512,acc_train:0.9921875,loss_train:0.03861704841256142\n",
      "epoch:21,step:8602,acc_val:0.8955078125\n",
      "epoch:22,step:8603,acc_train:0.984375,loss_train:0.049936920404434204\n",
      "epoch:22,step:8703,acc_train:0.9765625,loss_train:0.0579567514359951\n",
      "epoch:22,step:8803,acc_train:0.9765625,loss_train:0.07298360764980316\n",
      "epoch:22,step:8903,acc_train:0.9921875,loss_train:0.024945056065917015\n",
      "epoch:22,step:8993,acc_val:0.897265625\n",
      "epoch:23,step:8994,acc_train:0.96875,loss_train:0.047850869596004486\n",
      "epoch:23,step:9094,acc_train:0.9609375,loss_train:0.07911065220832825\n",
      "epoch:23,step:9194,acc_train:0.9765625,loss_train:0.04433465376496315\n",
      "epoch:23,step:9294,acc_train:0.9921875,loss_train:0.01732579991221428\n",
      "epoch:23,step:9384,acc_val:0.8943359375\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-05.\n",
      "epoch:24,step:9385,acc_train:0.9921875,loss_train:0.020172318443655968\n",
      "epoch:24,step:9485,acc_train:0.96875,loss_train:0.08318786323070526\n",
      "epoch:24,step:9585,acc_train:1.0,loss_train:0.010339044034481049\n",
      "epoch:24,step:9685,acc_train:0.984375,loss_train:0.08297153562307358\n",
      "epoch:24,step:9775,acc_val:0.9009765625\n",
      "epoch:25,step:9776,acc_train:0.9765625,loss_train:0.08582057058811188\n",
      "epoch:25,step:9876,acc_train:0.9765625,loss_train:0.05713866278529167\n",
      "epoch:25,step:9976,acc_train:0.984375,loss_train:0.040359314531087875\n",
      "epoch:25,step:10076,acc_train:0.9921875,loss_train:0.02708713710308075\n",
      "epoch:25,step:10166,acc_val:0.8951171875\n",
      "epoch:26,step:10167,acc_train:0.9765625,loss_train:0.057995930314064026\n",
      "epoch:26,step:10267,acc_train:0.9921875,loss_train:0.0410991832613945\n",
      "epoch:26,step:10367,acc_train:0.96875,loss_train:0.10161057114601135\n",
      "epoch:26,step:10467,acc_train:0.96875,loss_train:0.08139937371015549\n",
      "epoch:26,step:10557,acc_val:0.90078125\n",
      "epoch:27,step:10558,acc_train:0.984375,loss_train:0.06626217812299728\n",
      "epoch:27,step:10658,acc_train:0.9921875,loss_train:0.030578743666410446\n",
      "epoch:27,step:10758,acc_train:0.984375,loss_train:0.051686763763427734\n",
      "epoch:27,step:10858,acc_train:0.9609375,loss_train:0.05918395146727562\n",
      "epoch:27,step:10948,acc_val:0.896875\n",
      "epoch:28,step:10949,acc_train:0.9921875,loss_train:0.05616398900747299\n",
      "epoch:28,step:11049,acc_train:1.0,loss_train:0.008774418383836746\n",
      "epoch:28,step:11149,acc_train:0.9921875,loss_train:0.02138683758676052\n",
      "epoch:28,step:11249,acc_train:0.9609375,loss_train:0.07679789513349533\n",
      "epoch:28,step:11339,acc_val:0.8982421875\n",
      "epoch:29,step:11340,acc_train:0.984375,loss_train:0.0249757282435894\n",
      "epoch:29,step:11440,acc_train:0.984375,loss_train:0.03439420089125633\n",
      "epoch:29,step:11540,acc_train:0.9921875,loss_train:0.015574019402265549\n",
      "epoch:29,step:11640,acc_train:0.96875,loss_train:0.07108551263809204\n",
      "epoch:29,step:11730,acc_val:0.898828125\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-06.\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《时光重返四十二难》恶搞唐增取经一款时下最热门的动画人物：猪猪侠，加上创新的故事背景，震撼的操作快感，成就了这部恶搞新作，现正恶搞上市，玩家们抢先赶快体验快感吧。游戏简介：被时光隧道传送到208年的猪猪侠，必须经历六七四十二难的考验，才能借助柯伊诺尔大钻石的力量，开启时光隧道，重返2008年。在迷糊老师、菲菲公主的帮助下，猪猪侠接受了挑战，开始了这段充满了关心和情谊的旅程。    更多精彩震撼感觉，立即下载该款游戏尽情体验吧。玩家交流才是王道，讯易游戏玩家交流中心 QQ群：6306852-----------------生活要有激情，游戏要玩多彩(多彩游戏)。Colourfulgame (多彩游戏)，让你看看快乐游戏的颜色！精品推荐：1：《钟馗传》大战无头关羽，悲壮的剧情伴随各朝英灵反攻地府！2：《中华群英》将和赵云，项羽，岳飞等猛将作战，穿越各朝代抗击日寇。良品推荐：1：《赌王争霸之斗地主》易飞会在四角恋中会选择谁？是否最终成赌神呢？2：勇者后裔和魔王紧缠一起，前代恩怨《圣火伏魔录》将为您揭示一切。  3：颠覆传统概念，恶搞+非主流？！誓必弄死搞残为止《爆笑飞行棋》。4：《中国象棋残局大师》快棋和人机模式让畅快对弈！一切“多彩游戏”资讯，点击Colourfulgame官网http://www.colourfulgame.com一切“多彩游戏”感言，交流Colourfulgame论坛http://121.33.203.124/forum/【客服邮箱】：xunyiwangluo@126.com\">xunyiwangluo@126.com\">xunyiwangluo@126.com【客服热线】：020-87588437 : 游戏\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "import keras as kr\n",
    "import torch\n",
    "from torch import nn\n",
    "from cnews_loader import get_labels,get_vocab,process_file\n",
    "from model import TextRNN\n",
    "import numpy as np\n",
    " \n",
    "vocab_file = 'cnews.vocab.txt'\n",
    " \n",
    "class RnnModel:\n",
    "    def __init__(self):\n",
    "        self.label, self.label_dict = get_labels()\n",
    "        self.words, self.word_dict = get_vocab(vocab_file)\n",
    "        self.model = TextRNN()\n",
    "        self.model.load_state_dict(torch.load('model_params.pkl'))\n",
    " \n",
    "    def predict(self, message):\n",
    "        content = message\n",
    "        data = [self.word_dict[x] for x in content if x in self.word_dict]\n",
    "        data = kr.preprocessing.sequence.pad_sequences([data], 600)\n",
    "        data = torch.LongTensor(data)\n",
    "        y_pred_cls = self.model(data)\n",
    "        class_index = torch.argmax(y_pred_cls[0]).item()\n",
    "        return self.label[class_index]\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    model = RnnModel()\n",
    "    test_demo = ['《时光重返四十二难》恶搞唐增取经一款时下最热门的动画人物：猪猪侠，加上创新的故事背景，震撼的操作快感，成就了这部恶搞新作，现正恶搞上市，玩家们抢先赶快体验快感吧。游戏简介：被时光隧道传送到208年的猪猪侠，必须经历六七四十二难的考验，才能借助柯伊诺尔大钻石的力量，开启时光隧道，重返2008年。在迷糊老师、菲菲公主的帮助下，猪猪侠接受了挑战，开始了这段充满了关心和情谊的旅程。    更多精彩震撼感觉，立即下载该款游戏尽情体验吧。玩家交流才是王道，讯易游戏玩家交流中心 QQ群：6306852-----------------生活要有激情，游戏要玩多彩(多彩游戏)。Colourfulgame (多彩游戏)，让你看看快乐游戏的颜色！精品推荐：1：《钟馗传》大战无头关羽，悲壮的剧情伴随各朝英灵反攻地府！2：《中华群英》将和赵云，项羽，岳飞等猛将作战，穿越各朝代抗击日寇。良品推荐：1：《赌王争霸之斗地主》易飞会在四角恋中会选择谁？是否最终成赌神呢？2：勇者后裔和魔王紧缠一起，前代恩怨《圣火伏魔录》将为您揭示一切。  3：颠覆传统概念，恶搞+非主流？！誓必弄死搞残为止《爆笑飞行棋》。4：《中国象棋残局大师》快棋和人机模式让畅快对弈！一切“多彩游戏”资讯，点击Colourfulgame官网http://www.colourfulgame.com一切“多彩游戏”感言，交流Colourfulgame论坛http://121.33.203.124/forum/【客服邮箱】：xunyiwangluo@126.com\">xunyiwangluo@126.com\">xunyiwangluo@126.com【客服热线】：020-87588437']\n",
    "                 \n",
    "    for i in test_demo:\n",
    "        print(i,\":\",model.predict(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 98.4MB/s eta 0:00:01eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from keras)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
